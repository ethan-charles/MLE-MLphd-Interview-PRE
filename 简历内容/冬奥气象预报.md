# 冬奥气象预报

”参与‘基于人工智能的GRAPES体系预报产品特征挖掘与融合’国家重点实验项目, 为2022北京冬奥会开发出“多分辨率、多模式、多要素”的气象预报算法，主要负责风速和温度预报算法的开发。使用中国气象局提供的MESO-3km和GFS-10km气象预报模式以及超高精度观测数据，训练**U-Net+单格点回归层**模型，对两种模式进行偏差订正和融合；同时使用**SENET**赋予气象模型以可解释性。最终实现两米温度误差达到1.5摄氏度以下、10米u风和10米v风误差达到1m/s以下，达到冬奥会标准。该工作被[《焦点访谈》](http://tv.cctv.com/2021/12/17/VIDEOepfwATiE2EAmKMxtRWj211217.shtml)报道。*(Mentor: 赵颖)*“

GRAPES和MESO是中国气象局提供的天气预报模型，使用了一些解微分方程的算法。但是，在实际应用中，气象预报工作者很少直接使用 GRAPES/GFS 输出，这是因为简化的物理和热力学过程、有限的空间分辨率、或是气象工作者对气候系统过程的了解不足，会导致气象预报模型出现系统误差和偏差。因此，重要的 是对**不同**原始气候模型的输出进行**偏差订正和融合**，以产生更准确的气象预测。

#### 1. 使用数据

- GRAPES_MESO：为中国周边区域气象模式，由中国气象局数值预报中心提供。空间分辨率 10km，每隔 3 小时进行一次预报，在每个起报点一次性预报未来 30 小时的气象数据，步长为 1 小时，其中第一项即 0 小时的数据。由站点数据插值到格点，为 680×700矩阵。从中提取每天起报点为 0 时，预报时长为 0 小时、6 小时、12 小时、18 小时、24 小时的数据。每条数据的物理量包括：2 米温度（K）、10 米 u 风（m/s）、10 米 v 风（m/s）、相对湿度（%）。
- GRAPES_GFS ：全球中期天气预报系统 (GRAPES Global Forecast System)为全球气象模式，由中国气象局数值预报中心提供。模式产品空间分辨率0.25°× 0.25°。
- 观测真值数据由中国气象局数值预报中心提供，是华北地区**地面观测站点的观测结果经过插值**而得，分辨率为 1km。

预测 2 米温度时，模型使用%Y%m%d%H-0、%Y%m%d%H-6、%Y%m%d%H-12、%Y%m%d%H-18 和%Y%m%d%H-24 **五个数据点**去预测%Y%m%d(%H+24)-0，即 **24 小时后的零场**。每个历史时刻包含了 2 个 要素，即为 GRAPES_GFS 的两米温度和 GRAPES_MESO 的两米温度，因此输入为501×751×**10** 的三维矩阵，看作是具有 10 通道的图片；

预测 u 风和 v 风时，额外使用了**相对湿度**，使用%Y%m%d%H-0、%Y%m%d%H12、和%Y%m%d%H-24 三个数据点去预测%Y%m%d(%H+24)-0。每个历史时刻包含了 6 个要素，即为 GRAPES_GFS 和 GRAPES_MESO 的 u 风、v 风、相对湿度。因此输入为 501×751×18 的三维矩阵，看作是具有 18 通道的图片。对于预测目标%Y%m%d(%H+24)-0，使用该时刻的观测数据作为模型的训练目标，预测 2 米温度时大小为 501×751×1，看作是具有 1 通道的图片，预测 u 风、v 风时大小为501×751×3，看作是具有 3 通道的图片。

### 2. U-Net

U-Net是一个用于图像分割的神经网络。和普通的图像分类问题不同，U-Net所解决的医学图像分割问题需要对**每个像素点进行分类**。而气象预报偏差订正问题也是使用若干通道的格点预报作为输入，期望得到**相同大小**的订正 后格点预报作为输出，因此适合使用 U-Net 网络结构。

[![img](https://camo.githubusercontent.com/11b8f0d607f147e98cfaaf8a69230de3004ce268c0d1640f52c839d144b56cb5/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d32326163336430313565383532393361623534333232323165333134356639305f31343430772e706e67)](https://camo.githubusercontent.com/11b8f0d607f147e98cfaaf8a69230de3004ce268c0d1640f52c839d144b56cb5/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d32326163336430313565383532393361623534333232323165333134356639305f31343430772e706e67)

U-Net 网络包括收缩路径 (contracting path, U 形左侧) 和扩张路径 (U 形右侧)。

- 收缩路径包含着一种重复的结构：每次重复有两个 3*3 的**卷积层**、一个ReLU 层和一个步长为 2 的 2*2 max-pooling；每次下采样会使特征通道的数量增加一倍。
- 扩展路径也是由若干重复结构组成的：每次重复先利用卷积将特征通道的数量减少一半，同时特征图的大小增加一倍，然后将**反卷积**结果与收缩路径中相应的特征图拼接起来，以此来形成跳跃连接。由于收缩路径中的要素图尺寸略大，因此进行修剪之后才能拼接。在拼接后的要素图上执行两次 3*3 卷积。最后一层的卷积核大小为1*1，它将 64 通道的特征映射转换为具有特定类别数的结果。

```
class ResNetUNet(nn.Module):
    def __init__(self, n_class):
        super().__init__()

        self.base_model = models.resnet18(pretrained=True)
        self.base_layers = list(self.base_model.children())

        self.layer0 = nn.Sequential(*self.base_layers[:3]) # 【注1】
        self.layer0_1x1 = convrelu(64, 64, 1, 0)
        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)
        self.layer1_1x1 = convrelu(64, 64, 1, 0)
        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)
        self.layer2_1x1 = convrelu(128, 128, 1, 0)
        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)
        self.layer3_1x1 = convrelu(256, 256, 1, 0)
        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)
        self.layer4_1x1 = convrelu(512, 512, 1, 0)

        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) ##【注2】

        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)
        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)
        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)
        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)

        self.conv_original_size0 = convrelu(3, 64, 3, 1)
        self.conv_original_size1 = convrelu(64, 64, 3, 1)
        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)

        self.conv_last = nn.Conv2d(64, n_class, 1)

    def forward(self, input):
        x_original = self.conv_original_size0(input)
        x_original = self.conv_original_size1(x_original)

        layer0 = self.layer0(input)
        layer1 = self.layer1(layer0)
        layer2 = self.layer2(layer1)
        layer3 = self.layer3(layer2)
        layer4 = self.layer4(layer3)

        layer4 = self.layer4_1x1(layer4)
        x = self.upsample(layer4)
        layer3 = self.layer3_1x1(layer3)
        x = torch.cat([x, layer3], dim=1)
        x = self.conv_up3(x)

        x = self.upsample(x)
        layer2 = self.layer2_1x1(layer2)
        x = torch.cat([x, layer2], dim=1)
        x = self.conv_up2(x)

        x = self.upsample(x)
        layer1 = self.layer1_1x1(layer1)
        x = torch.cat([x, layer1], dim=1)
        x = self.conv_up1(x)

        x = self.upsample(x)
        layer0 = self.layer0_1x1(layer0)
        x = torch.cat([x, layer0], dim=1)
        x = self.conv_up0(x)

        x = self.upsample(x)
        x = torch.cat([x, x_original], dim=1)
        x = self.conv_original_size2(x)

        out = self.conv_last(x)

        return out
```

【注1】python中的单星号*： 1. 将参数以元组形式传入(如*args) 2. 解压，把list变成若干参数

 双星号 **：将参数以字典形式传入(如** kwargs)

【注2】`self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)`

**Trick：随机深度**

Stochastic Depth 的理念和 Dropout 类似，将 ResNet 看作多个 ResNet 的集合，只不过后者是在训练时随机失活一些神经元，测试时使用完整的网络；前者是随机失活一些卷积层，或者更准确地说，是通过只保留 shortcut 通路的方式随机跳过 ResNet 中的一些 Residual Blocks，使得模型更鲁棒（**【正则化方法】**），而且由于训练时计算量的减少从而降低训练时间（电费）。

[![img](https://camo.githubusercontent.com/7ada347e1e1ed1ace05699b818f8056bc395e462da9a31a790d8e2c40bda7a88/68747470733a2f2f706963342e7a68696d672e636f6d2f38302f76322d66643264303232336366333235313333313566303936663734306438346230625f31343430772e6a7067)](https://camo.githubusercontent.com/7ada347e1e1ed1ace05699b818f8056bc395e462da9a31a790d8e2c40bda7a88/68747470733a2f2f706963342e7a68696d672e636f6d2f38302f76322d66643264303232336366333235313333313566303936663734306438346230625f31343430772e6a7067)

每一层都有一个存活率$p_L$. 如果失活，就是一个恒等变换。

模型训练好后，在测试阶段，每个 [![[公式\]](https://camo.githubusercontent.com/736c550a618ebc44db1fdabf619f8bbb9212df51911c86bbfd78bbc2b5e23b8e/68747470733a2f2f7777772e7a686968752e636f6d2f6571756174696f6e3f7465783d665f6c2532382e253239)](https://camo.githubusercontent.com/736c550a618ebc44db1fdabf619f8bbb9212df51911c86bbfd78bbc2b5e23b8e/68747470733a2f2f7777772e7a686968752e636f6d2f6571756174696f6e3f7465783d665f6c2532382e253239) 的输出必须**乘上它的存活系数**：

[![[公式\]](https://camo.githubusercontent.com/d6dee9028484d5a3bce56ab8044f6e20bb77841763b03beb9a434822cb148b8c/68747470733a2f2f7777772e7a686968752e636f6d2f6571756174696f6e3f7465783d2535432535432b785f6c253344705f6c2b25354363646f742b665f6c253238785f2537426c2d31253744253239253242785f2537426c2d31253744)](https://camo.githubusercontent.com/d6dee9028484d5a3bce56ab8044f6e20bb77841763b03beb9a434822cb148b8c/68747470733a2f2f7777772e7a686968752e636f6d2f6571756174696f6e3f7465783d2535432535432b785f6c253344705f6c2b25354363646f742b665f6c253238785f2537426c2d31253744253239253242785f2537426c2d31253744)

### 3. 逐点回归层

气象预报的误差不仅包含由于简化的气象活动导致的系统误差[34]，还包含每个格点由于插值等原因导致的特定格点的误差[35-36]。 U-Net模型通过不同尺度的卷积操作学习局部区域模式，从而降低系统误差；为了降低特定格点的误差，本文的实验增加了逐点回归层，该层与普通的卷积操作类似，只不过不使用共用的卷积核，而是对空间的不同点都使用不同的卷积核，这样相当于对每个格点分别做线性回归。逐点回归层的输入是 U-Net 模型的输出和原始输出拼接起来的结果，即 (ch+1) 个通道，其中 ch 是原始通道数。

**Trick：使用残差进行训练。**

### 4. SE-block

加入通道注意力提供可解释性，同时SE-block一般都会有提升。

[![img](https://camo.githubusercontent.com/d4987593fd954c7c46211e70599aa5af237960cc4e4cd464ab774367c4cfcd7f/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d66363733336361663733633338633337313835303263323263666462303166315f31343430772e706e67)](https://camo.githubusercontent.com/d4987593fd954c7c46211e70599aa5af237960cc4e4cd464ab774367c4cfcd7f/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d66363733336361663733633338633337313835303263323263666462303166315f31343430772e706e67)

总体模型结构：

[![img](https://camo.githubusercontent.com/581d352e38befa1ec071462ac67fade9bfde6b0ae8dd44c3ec51fad27a9fe0f7/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d62666532636631663936336434633965623366633136393363343938343964665f31343430772e706e67)](https://camo.githubusercontent.com/581d352e38befa1ec071462ac67fade9bfde6b0ae8dd44c3ec51fad27a9fe0f7/68747470733a2f2f706963312e7a68696d672e636f6d2f38302f76322d62666532636631663936336434633965623366633136393363343938343964665f31343430772e706e67)

caveat: 温度和风速直接用生成式方法就可以，因为这已经完全能够保证真实性；而降水为了保证真实性（不能这个格点在降水、下一个格点没有降水），则必须要使用对抗生成网络（MSGAN）。