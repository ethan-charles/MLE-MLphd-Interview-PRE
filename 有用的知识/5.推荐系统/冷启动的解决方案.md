# 冷启动的解决方案

### 冷启动面临的挑战：

在训练的时候，老用户的样本在数量级上碾压新用户的样本，导致**模型主要拟合老用户的行为模式，忽略了新用户**。在这种情况下，增加几个对新用户友好的特征（比如**年龄、性别**等），因为主导模型的老用户不care（影响老用户推荐结果的主要是其过去历史行为序列，而非人口属性），加了也是白加。先看看下面这两种不太可行的做法：

- 给新用户的样本加权。行是行，但是有两个问题不太好解决，一是如何设定给这些新用户的权重，二是，毕竟老用户才是给我们贡献KPI的主力，给新用户加权，等于变相削弱老用户，可能得不偿失。
- **干脆分家，就只拿新用户的数据单独训练一套模型，只服务新用户**。也不是不行。但是，也有两问题不好解决，一是新用户数据量少，底层embedding和中间的dense weight可能训练不好；二来，单独训练，单独部署，有点浪费资源。

正文开始之前，先提前声明几点：

- 本文中所提及的新用户是一个泛称，未必是第一次登录、毫无动作的纯新用户，也包括那些虽然距首次登录已经过去许久，但是鲜有活动的用户。其实，文中的概念算是“**低活用户（即，用户历史行为序列很少的那些用户）**”；
- 本文中所提观点，和“**收集用户信息是新用户冷启top priority**”的观点并不矛盾。相反，以下算法技巧的目的，就是为了能够让模型更重视那些对新用户友好的**特征**，让这些特征真正发挥作用。



对于新用户冷启，**top priority**肯定还是**尽力收集用户的数据**。这需要我们的产品思维，比如在用户刚注册的时候，就让用户填写兴趣；或者从其他产品来了解用户。

但是，仅靠收集数据也是不够的。比如：在一个成熟的app中，老用户的样本碾压新用户样本，主导了模型。徒增了几个new user friendly的特征，模型也不会重视。

因此，也还需要一些算法上的技巧，让收集到的新用户信息，能够真正发挥作用。



### 解决方案一. 加强重要区分性特征

上文说到，新老用户的行为模式有着较大差异，老用户更加关注用户历史行为，而新用户则需要更加关注用户年龄、地理位置等属性信息。我们希望把这一知识告诉模型，让模型对新老用户能够**区别对待**。

首先，我们要构造能够**显著标识新用户的特征**，比如：用户是否登录、首次登录距今时间、交互过的item的个数（交互item很少的用户也叫新用户，不管TA什么时候注册的）

#### 强bias特征加得浅

可以把这些强bias特征加得离final logit近一些，让它们对最终loss的影响更**直接一些**。比如：$Logit_{final} = Logit_{ordinary}+Logit_{bias}$

- $Logit_{ordinary}$由其他特征获得需要经过复杂且深的DNN结构
- 而$Logit_{bias}$由以上强bias特征贡献的，只是将这些强bias特征通过一个LR或一层fully connection就得到

这种思想和Wide & Deep类似，强Bias特征就是Wide端。

#### 强bias特征当裁判

方法二，将这些强bias的特征，喂入SENet，用来决定其他特征的重要性

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSPibuUD4gtibOpsWCyhBdwpGLBsUCKFUffj6mthFMx2T1W8vbGIpibMRruQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



- 强bias特征作为MLP的输入，经过sigmoid激活函数后，输出是一个N维度向量，N是所有field的个数，这就是我们得到的N个field的attention权重。将其按位乘到各field的embedding上，起到增强或削弱的作用。比如：

- - 比如产品设计不允许未登录用户点赞、评论，那么新用户样本中的相关特征的重要性“应当”为0
  - 用户点击哪个站外广告被引入app，这个信息只对新用户有用（权重应该大），对老用户意义就不大了（权重应该小）

- 加权后的各field embedding再拼接起来，喂入上层DNN

这样做，相比于将所有特征“一视同仁”、一古脑地喂入DNN最底层等候上层DNN筛选，更能发挥那些**对新用户友好的重要特征**的作用。这样做似乎就能够解决开篇提出的问题了：对于新用户，模型会给用户属性field分配较大的权重，而对于老用户，会给历史行为分配较大的权重。



### 解决方法二、借鉴多领域学习

正如开篇所说，**为了避免新用户数据被老用户淹没，干脆分家，用新用户的数据单独训练一个模型只服务新用户**。但是有两个问题不好解决，一是新用户数据少，单独训模型可能训不好；二是，单独训练+部署，有点浪费资源。

其实这个问题属于**multi-domain learning**的解决范畴。不要和multi-task learning相混淆，multi-domain learning研究的是如何将多个相关渠道的数据放在一起训练，数据的**distribution是不一样**的；而multi-task时多任务学习。multi-domain方面的工作并不多，让我们看看阿里近年来在这一领域发表的两篇文章。**提醒读者，尽管两篇文章的初衷都不是针对新用户，但是在阅读过程中，我们可以代入new user domain vs. old user domain的场景**。这里，我们也可以考虑之前说过的跨域推荐中的其他方法。

#### STAR结构

一篇是《One Model to Serve All: Star Topology Adaptive Recommender for Multi-Domain CTR Prediction》。这篇文章研究的是，如何训练并部署一个模型，就能**胜任“首页推荐”、“猜你喜欢”等多个领域（不同域的distribution不一样）**。

第一个改进：Partitioned Normalization

- 每个域学习各自的batch normalization。

  训练阶段：

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSP1ftodsRl7y9lfcqRicrwG5yYUFvBFKIXTpoJldyZVblACdeY25xWa5A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

​	$\gamma_p, \beta_p$ 是要全局学习的域p的scaling和bias，每个域都学一个不一样的；

​	测试阶段，我们对不同的域都使用那个域特有的mean和variance，而不是把所有域的都混在一起。

这是因为BN本来的假设是数据都是iid的，而multi-domain中只有在每个域中的数据才是iid的，不同域的数据不是iid的。如果我们还用普通的BN，在测试过程中记录的mean 和 variance就是不同distribution混在一起的结果，这显然不是我们想要的。

第二个改进：

- 将domani id这样的强bias特征，通过一个浅层网络，加得离final logit近一些。这一点就是我们在上一章节介绍的技巧。

第三个改进，就是所谓的星型拓扑结构，也就是论文标题的来源。简单来说，**就是每个domain要经过的final dense weight是domain specific part和shared part融合而成**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSPzxtFPtNQNWvR4GMvAqNicNsx7QSjPNXzw6xfe3dNQNInbMBIeIB8XicQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSP0diarkSRJ5NPKicAiaM2iapvZoiasLDsJrWVW90fJ8koDictM52T03DhJMrg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- $W_p*$是domain 'p'的样本**最终要经过的final weight，**![图片](data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)其中，$W_p$是domain "p"独有的weight，只让domain "p"的样本参与迭代更新; W是shared weight，所有domain的数据都要参与更新。两者做的是element-wise multiplication（哈达玛积）

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSPTg2wdjPOWDj1T5VwbLjobb78oBjkHWn9YlbIFqZJMulmZ1PaCQ2QvQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

我有点不太好评价这种结构。其实想结合domain specific information与shared information也不算什么新概念，比如下面两种：

- domain specific weight与shared weight是并联的关系，样本信息同时经过domain specific weight和shared weight向上传递，$Logit_{final} = Logit_{share}+Logit_{domain}$
- 模仿早先multi-task learning中常见的share bottom结构，先有共享的底层shared weight，各个domain再在上面串联上domain specific weight。预测时，样本先经过shared weight，再经过domain specific weight向上传递，$Logit_{final} = F_{domain}(F_{share}(x))$

文中并没有给出哈达玛积这种融合方式相对于我在上文提出的两种融合方式的优势，或许没啥大道理，又是实验得出的结论。我自己给出的理由只能是：

- 无论是domain specific weight与shared weight是并联还是串联，信息所经过的每一层，都只属于单一通道（要么是domain specific，要么是share），融合得并不彻底；
- 而$W_p \odot W$，信息流过的每一层都是domain specific weight和shared weight融合后的，融合得更充分。



## HMoE结构

AliExpress的文章《Improving Multi-Scenario Learning to Rank in E-commerce by Exploiting Task Relationships in the Label Space》聚焦于**多国家**场景下的推荐(也是multi-domain)。这个场景，和我们新用户的场景更加类似一些，多个国家的人口迥异，市场进入有早有晚，相对于先发国家庞大的用户基数和丰富的行为，**后发国家的用户少、行为少，可以类比于“新用户冷启”的场景**。

这篇文章提出的HMoE与STAR完全相反，没有所谓的shared weight。其原理假设是：

- A国家中，有些用户a的行为和B国的用户很像，所以，让B国的DNN给a打分也很靠谱，异域模型打分的借鉴意义大；反之，异域模型打分的借鉴意义小。
- 回到我们新用户的场景下，**用老用户模型给新用户打分，可能对部分新用户也是大有裨益的**。

具体做法上：

- 无论哪个域的样本，都要经过**所有domain的DNN打分**（下面公式中的S），
- 最终得分，是各个域打分的**加权平均**。权重（下面公式中的W）由一个gate netowrk根据输入样本，个性化决定。

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSPhcAU08yjkuvERx4elYqiamIMdAGuRyibhsmDzk4B9tKKN2XzayrtRRpA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 训练时，**domain=t的样本，只能更新自己的，对其他domain的DNN都要stop gradient**。这一点也相当直觉，毕竟其他domain的DNN帮domain t打分是副业，不能强求其他domain的DNN为domain t上的loss负责。

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSPU8y2OQjTg8cvqqoia3ZuX1gxtk17PkMpc00Qr6ty5bhbHpUpaxkO8ww/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



### 解决方法三、获得对新用户友好的初值

这种方法的思路是，新用户训练困难是因为数据少。但是，**如果新用户的初始值并非随机，而是已经非常靠谱了，通过少量数据+几次迭代，就能收敛到不错的用户表示**，岂不妙哉！

#### 用Group Embedding代替新用户的Id Embedding

介绍一种我自己设计的方法，用来获取良好的new user id embedding初值，在一些场景下的效果还不错。

我的方法的前提假设是：

- user id embedding是最具个性化的特征输入，在老用户推荐中发挥了极其重要的作用，DNN也非常重视这个特征（e.g., 接在user id embedding上方的weight比较大）。
- 但是问题就在于，由于新用户的user id embedding出现次数少，经过有限次训练，**new user id embedding还离最初随机初始化的结果不远**，训得不好。

既然user id embedding那么重要，而**新用户的user id embedding质量却那么差**，那么能不能找到一个替代方案？这时，Airbnb的经典文章《Real-time Personalization using Embeddings for Search Ranking at Airbnb》给我提供了一种思路。在Airbnb的实践中，由于booking这个行为太稀疏，所以绝大多数用户都是“新用户”，而Airbnb的思路就是根据规则将用户划分为若干用户组（比如，“讲英语，使用苹果手机”的用户群，和“讲西班牙语，使用Android手机”的用户群），然后**用user group embedding代替单独的user id embedding参与后续训练与预测**。

![图片](https://mmbiz.qpic.cn/mmbiz_png/ictibgSY4QzEynVxdb44neIRq0bP6jibTSPZApPbThF9LVTZS2A4khfMoTpZ3tH0CqibJ2goQ8iaKeNtsLwlgEmAzfA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

基于以上假设，解决思路是：

- 将user id embedding（无论新老用户）拆解成$E_{uid} = E_{group} + E_{personalresidual}$

- - **注意这个分群是“初始用户群”，划分时，只能依靠那些对新用户友好的特征**，比如：年龄、性别、安装那些（种类）的app，是被哪个（类）广告拉新进来的、......

- - $E_{group}$是“初始的用户群”的embedding。
  - $E_{personalresidual}$代表自用户进入app之后，随着在app内部行为越来越丰富，他距离当初“初始用户群”embedding的个性化残差

- 对于老用户，原来的方法是直接学习每人各自的user id embedding，现在是改学，所有个性化信息都包含在这个个性化残差里了。

- 对于新用户

- - 训练时，尽管一开始$E_{personalresidual}$还是随机向量，但是**毕竟是在已经训练好的$E_{group}$周围**（怎么训练，下面会讲），对于上层的DNN来说，也算是一个不错的初始值!
  - 预测时，inference server遇到纯新用户，新用户的user id embedding被用户群embedding $E_{group}$代替，强于之前模型用全0向量填充或者随机初始化的方法。

目前还遗留一个问题，就是怎么得到$E_{personalresidual }$？我的方法是采用**预训练**的方法

- 如上所述，分群是“初始用户群”，划分时，只能依靠那些对新用户友好的特征，比如：年龄、性别、安装那些（种类）的app，是被哪个（类）广告拉新进来的、......

- 借鉴Airbnb的方法，用类似word2vec的方法获得各$E_{group}$，具体来说，

- - 正样本：某个新用户的$E_{initgroup}$，与其交互过的**item embedding**在向量空间上应该足够近，所以交互过的item embedding就作为正样本出现
  - 负样本：随机采样一些item embedding作为负样本。

- 注意，在我的实践中，进行以上预训练，**只采用新用户的数据，不用老用户的数据**。

- - 这么做是因为，老用户交互的item，主要是由推荐系统根据用户历史推荐出去的，和用户的初始**元信息**（比如，年龄、性别、App等）关系已经不大了。引入老用户数据，反而引入了噪声

- 预训练完毕，将各init user group embedding保存起来

注意，在正式训练的时候，

- $E_{group} $**对于老用户要stop gradient**，毕竟年代久远，init user group embedding不应该再为老用户推荐结果上的loss负责。也防止规模巨大的老用户数据，将已经训练好的group embedding带偏
- **至于新用户，最好对$E_{group }$也stop gradient**，一来新老用户一致，方便实现；二来，我们希望信息都积累在personal residual上，而不是在group embedding上。



#### 解决方法四、利用user/item的内容信息

思考一个问题：什么导致了冷启动问题？是**user-item交互数据的缺失**。而user/item本身的内容信息是全的。那么，我们就自然应该利用好user/item本身的内容信息！

如果只使用collaborative filtering方法，那么就只考虑了user-item交互，而没有考虑user-user和item-item相似度信息。所以，不妨综合 user-item交互、user-user 相似度、item-item相似度构建图网络，然后利用deepwalk等node2vec方法得到user和item的embedding向量。这样，我们就把新用户/item根据相似度信息“插入”到图中的合适位置，然后得到比较好的初始embedding。

另一个更简单的做法参考Airbnb的文章 Improving Deep Learning For Airbnb Search

既然冷启动问题其实就是：新的item缺少一些用户**交互信息**(e.g. number of bookings, clicks, reviews),而其他特征(price, location)是不缺少的。那么，问题变成了：**如何根据已有的特征去预测这些用户交互信息呢？如果我们能够准确地预测出来用户交互信息，那么冷启动问题就解决了！**

baseline方法是用一些default值去填充缺失的用户交互信息；**而Airbnb的方法是用离new item地理位置临近的、且客人数相等的老item的用户交互信息平均值来填充缺失值**。

> For example, to estimate the number of bookings for a new listing with a two person guest capacity, it took the **average** number of bookings for all listings within a small radius of the new listing with a capacity of two. 

Airbnb的文章总是这样朴实无华...但是很实用。



# 总结

- 技巧1：要把new user friendly特征加到合适的位置，比如加得离loss更近一些，再比如作为gate的输入，衡量其他特征的重要性。
- 技巧2：将新老用户看成两个domain，借鉴**multi-domain learning**的经验，让老用户模型能够助力新用户（**跨域迁移学习**），又不至于过分主导。
- 技巧3：新用户的初值非常重要。例如用user group embedding代替user id embedding的算法。
- 技巧4：利用好user/item的内容信息，我们可以把新用户根据内容信息的相似度插入到user-item交互图中的合适位置；也可以直接根据内容信息来预测交互信息。