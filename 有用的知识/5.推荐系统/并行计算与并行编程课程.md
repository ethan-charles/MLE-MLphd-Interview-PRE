# 并行计算与并行编程课程

### Lecture1 Introduction

![image-20220806121755685](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806121755685.png)

平行计算与分布式计算的区别：

- 都是用很多台电脑；
- 平行计算更倾向于时间同时（更快），分布式计算更倾向于空间同时

![image-20220806122337147](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806122337147.png)

（分布式：资源分享，沟通、传递信息，跨很远的距离，甚至全国各地； 平行计算：统一管理，距离不能很远，不然传递信息延时很大）

![image-20220806123341097](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806123341097.png)

![image-20220806123529733](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806123529733.png)

- **FLOPS**：注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。
- **FLOPs**：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。（https://zhuanlan.zhihu.com/p/137719986）

![image-20220806124344719](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806124344719.png)

![image-20220806124448259](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806124448259.png)

![image-20220806124522985](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806124522985.png)



![image-20220806130633770](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806130633770.png)

- 摩尔定律：集成电路上可以容纳的晶体管数目在大约每经过18个月便会增加一倍。摩尔定律失效的原因主要是高温+漏电。

- **异构计算**（英语：Heterogeneous computing），又译**异质运算**，主要是指使用不同类型[指令集](https://zh.m.wikipedia.org/wiki/指令集)和[体系架构](https://zh.m.wikipedia.org/w/index.php?title=体系架构&action=edit&redlink=1)的计算单元组成系统的计算方式。常见的计算单元类别包括CPU、GPU等协处理器、DSP、[ASIC](https://zh.m.wikipedia.org/wiki/ASIC)、[FPGA](https://zh.m.wikipedia.org/wiki/FPGA)等。

  异构计算近年来得到更多关注，主要是因为通过提升CPU时钟频率和内核数量而提高计算能力的传统方式遇到了散热和能耗瓶颈。而与此同时，GPU等专用计算单元虽然工作频率较低，具有更多的内核数和并行计算能力，总体性能-芯片面积比和性能-功耗比都很高，却远远没有得到充分利用。



#### Lecture2. 并行计算机与并行模型的分类

![image-20220806130834465](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806130834465.png)

按照CPU分类：Flynn分类法

![image-20220806131038283](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806131038283.png)

![image-20220806131142208](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806131142208.png)

（单核，只能串行。）

![image-20220806131712313](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806131712313.png)

（目前GPU最常用的方法，多核）

![image-20220806132209607](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806132209607.png)

每个指令可以不一样

![image-20220806132533232](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806132533232.png)

（完全没有限制）



Memory architecture classification:

![image-20220806132802122](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806132802122.png)

![image-20220806133654267](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806133654267.png)

不同的core共享share memory



![image-20220806144057694](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806144057694.png)

latency 一致和不一致。一致：cpu directly access memory; 不一致：hierarchical架构，所以一个cpu access local memory 的时间自然和其他memory的时间不一样。

![image-20220806145526693](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806145526693.png)

cluster：单一的administrator管理的，环境是完全相同的；

![image-20220806145734825](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806145734825.png)

地址空间不共享（隔离），必须要沟通才能够获得资料。

programming model的分类：

![image-20220806150505104](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806150505104.png)

abstraction：定义API。

一般来说，message passing model 对应 distributed memory; shared memory model 对应shared memory.

MPI：message passing interface，就是针对信息传递来说的。

![image-20220806150624896](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806150624896.png)

![image-20220806150707357](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806150707357.png)

pthread: low-level

openmp: high-level

![image-20220806150935083](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806150935083.png)

![image-20220806151043124](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806151043124.png)

share: 快，不能scale（一个电脑没有多少核），就是serial code

message passing: communication可以控制，不是serial code，必须send 和 receive，防止卡在那里；有overhead

![image-20220806151426695](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806151426695.png)

#### lecture3 超级计算机

![image-20220806151508093](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806151508093.png)

![image-20220806151951518](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806151951518.png)



rack：机架；server：服务器，最小的单位为1U server，但是这个空间比较小，不能放进很多的GPU（GPU卡占空间）。如果有很好的冷却系统，就可以把server弄得更加密集。server里面有cpu、gpu，构成异构计算。

![image-20220806152249429](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806152249429.png)

用HPL benchmark衡量看谁更快

![image-20220806152603370](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806152603370.png)

可以对matrix进行各种的切割，不管怎么切割（tune hyperparameter）都行，只要FLOPS最高。比如可以切割使得每一部分可以塞进cache

![image-20220806231306871](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806231306871.png)

hardware昂贵（GPU）

config: tune hyperparameter, 放进cache，否则变慢

library: MPI (send, receive, broadcast...) 很多communication的方式，怎么高效实现，使得physical link有较少mismatch

![image-20220806231507603](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806231507603.png)

Rpeak：纯计算，不考虑communication

GPU计算能力比CPU多很多，作为加速器

![image-20220806232145620](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806232145620.png)

![image-20220806232237346](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806232237346.png)

网路



不同类型的处理器：CPU/GPU

![image-20220806233203762](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806233203762.png)

CPU有计算能力的限制，因为要通用。GPU 都在同一张卡里，所以bandwidth更大。

![image-20220806235344326](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220806235344326.png)

core越少，freq越高，增加加速的能力

![image-20220807160222959](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220807160222959.png)

卡：device；cpu卡：host

![image-20220807160738643](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220807160738643.png)

不同processor有不同的instruction set，有些instruction没有support；Intel：只要能run在普通的CPU上，就能够run在Phi上。

![image-20220807160856068](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220807160856068.png)

matrix 很适合data parallelism

![image-20220808095532760](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808095532760.png)

TPU：专门support乘法这个动作，因为logic gate已经烧死了；GPU是vector在做计算；CPU一个一个element在做计算。



##### Interconnect & Network technology

![image-20220808095842943](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808095842943.png)



沟通：shared-memory/ message passing；shared memory快，但是scale被bond在一台机器里面 ->需要用网络沟通。除了网络开销，同步化也很重要（找同步点的位置），不然会算出错的结果，如果读到旧的信息的话。network link topology也很重要。

![image-20220808101216408](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808101216408.png)

- scalability：node不断增加，效能会不会decay很严重，导致最后不能跑？switch的port数量也是有限的（128个）。
- performance：传送资源的速度
- resilience：link和network很容易坏掉，怎么避免fail

最底层：physical连接；网络层：routing （diameter越大，最糟的时间更大），fault tolerance：一个edge被砍掉，还有没有办法透过其他的router连接到；MPI：系统搭建完成之后，怎么implement algo，什么communication pattern，有很多传递方式（如broadcast）

![image-20220808101245201](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808101245201.png)

本堂课的topo很简单。latency是根据topo的diameter来决定的；resilience: 砍掉多少个edge可以让这个graph变成disconnected的graph；cost：需要几个edge：scalability：如果degree越多，需要port越多，scalability越差。

![image-20220808111623633](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808111623633.png)

ring和linear array一样，只不过把最后一个和第一个接起来。

![image-20220808112221912](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808112221912.png)

![image-20220808112252812](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808112252812.png)

![image-20220808141031437](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808141031437.png)

hardware: port 拉cable不能非常远。每一个switch可以接非常多的port，不同rack之间会有链接。

![image-20220808141519450](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808141519450.png)

infiniband是唯一一个提供high throughput, low latency. 只要有钱，直接选择infiniband。

![image-20220808141611488](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808141611488.png)

为什么infiniband好这么多？因为infiniband的protocal和ethernet不同。ethernet是有冲突之后在回退；inifiniband是reservation。

RDMA：remote direct memory access，不请求中断，直接往内存中写数据

![image-20220808141926959](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808141926959.png)

##### I/O & Storage technology

![image-20220808142249573](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808142249573.png)

![image-20220808142633940](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808142633940.png)

![image-20220808143318396](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808143318396.png)

solution：新的hardware出现；parallell IO：同时对资料做读写。storage node physically连到compute node，这样可以提升带宽。MDS：metadata，可以快速找到档案位置（centralize control）

MPI的每一个process怎么去和每一个storage node去沟通？->额外的library support

![image-20220808143304378](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808143304378.png)

compute node和资料之间加一个buffering；如果没有buffer，那么IO量很多时候不稳定，output瞬间出来大部分资料，IO经常bursting -> compute node和IO node该reserve多少bandwith？

这个buffer就是解决burst。暂存到IO node的memory中

![image-20220808144710675](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808144710675.png)、

计算、网路、IO的配合，自己写的program有没有考虑到系统架构。



### Parallel Program Analysis

##### Speedup & Efficiency

![image-20220808145818431](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808145818431.png)

自己画speedup图。sublinear：因为communication，增长是n平方的

superlinear：input data可以塞进memory甚至cache，communication速度减少

efficiency：speed up 除以 processor数量，相当于归一化

![image-20220808150016661](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808150016661.png)

不是所有程序都能够并行化，比如一开始的init

![image-20220808150220996](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808150220996.png)

前面绿色的是不能并行化的，后面是可以并行化的。



##### Strong scalability & Weak Scalability

![image-20220808150726817](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808150726817.png)

sort 1000 个数字，strong scaling就是增加core，看time的减少程度，很难达到linear scale-up。

![image-20220808151140758](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808151140758.png)

增加compute node的时候，problem size也成比例增加。比如1个core-> sort 1000个；2个core->sort 2000个。一般情况下，execution time会维持不变。

![image-20220808202228008](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808202228008.png)

##### The complexity Analysis

![image-20220808202736870](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808202736870.png)

computation 在不同电脑上同时发生；

communication的计算：$q$: 有多少消息需要传递；n：有多少int/byte; $T_{data}$: 传递一个item需要的时间。

![image-20220808203110179](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808203110179.png)

n个数字求sum：两台电脑，第一台电脑先把资料砍一半，送到第二台电脑去；各自算partial sum，第二台电脑把结果算好，送回第一台电脑。分别计算commu/compu的复杂度。

commu：步骤2和4都是送一个message，所以q都是1；步骤2的时候传送一半的资料，所以是$n/2$. 

![image-20220808210006563](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808210006563.png)

scale增大之后（m个processor）

![image-20220808210556029](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808210556029.png)

phase1：第一个processor给其他processor送去数据，送的数据量为$n/m$, 送的message为m个

phase2：加总

phase3：全部收到master



平行度越大，复杂度越低。

N：有几个processor。如果是optimal的，$O(T_p) \times N = O(T_s)$.

# Chap5. Message-Passing Programming: MPI

#### MPI Introduction: History & Evolution

![image-20220808213400108](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808213400108.png)

程序员透过interface来使用api，MPI是用socket programming传递资料。但MPI太复杂了，我们只需知道API。

![image-20220808213513554](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808213513554.png)

![image-20220808214436170](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808214436170.png)

job：就是这个program，task是比job更小的单位

branch：每个processID不同，所以可以用作branch,读取不同的data partition，然后做相同的事情

runtime的时候不能create process

![image-20220808215547188](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808215547188.png)



#### Communitcation Methods



- 沟通的关联性。同步：打电话；异步：收email
- blocking：一个动作（如data transfer）要做完，才return；non-blocking：function call之后立刻return，不等commu做完就可以做compu

![image-20220808223659331](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808223659331.png)

![image-20220808224328649](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808224328649.png)

![image-20220808224352640](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808224352640.png)

async主要在于有message buffer，send的时候资料不会一次copy到对方来，而只是copy到buffer，等着对方call receive。

#### MPI API

##### Getting Start

![image-20220808230613601](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808230613601.png)

return value一定是error code

serial code是每个process都会执行的，如果有十个process，就执行十次。

![image-20220808233056452](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220808233056452.png)

rank ID是relative to group 的，

![image-20220809003145438](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809003145438.png)

![image-20220809003447495](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809003447495.png)

MPI_Comm_size: 一个group中有多少个进程

MPI_Comm_rank: task ID



##### Point-to-Point Communication Routines

![image-20220809130200291](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809130200291.png)

blocking: sync; non-blocking: async

- buffer：起始位置，需要事先allocate buffer, 否则会导致segmentation fault；

- type（enumerate），count：相乘得到size
- tag: 想要receive的message是哪一个

- request: 检查non-blocking的request state是完成，才去取里面的值

- status：blocking的，记录receive动作的资讯（比如receive多少byte）

![image-20220809130302541](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809130302541.png)

send和receive一定要对在一起，否则会卡在中间。

注意传的是x的address；每个process run在不同的memory space上，所以x的值是不共享的哦

![image-20220809131009310](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809131009310.png)

直到req1是完成的时候，才会返回。

wait是一直在那里blocking，test只是去看状态是什么，把他return回来

##### Collective Communication Routines

![image-20220809131952497](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809131952497.png)

point2point是pairwise的沟通，这个很慢；比如一开始/最后把所有资料平分/收集回来，需要用collective commu。只要是collective，一定是blocking，而且是大家一起block。这个容易使用，但是容易成为性能瓶颈。

root：sender；commu：communicator，一个group。broadcast之后，每个process的buffer中内容都变成了7.

![image-20220809132950263](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809132950263.png)

sendcnt和receivecnt一般都是相同的值，1代表每一个人receive1个element。

![image-20220809133004284](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809133004284.png)

![image-20220809133426039](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809133426039.png)



##### Group and communicator Management Routines

![image-20220809150641927](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809150641927.png)

group 和 communicator是不一样的东西

- MPI_Comm_group: 从communicator中取得

![image-20220809180530711](C:\Users\jiayu\AppData\Roaming\Typora\typora-user-images\image-20220809180530711.png)