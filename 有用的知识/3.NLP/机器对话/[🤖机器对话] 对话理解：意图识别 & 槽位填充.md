# [🤖机器对话] 对话理解：意图识别 & 槽位填充



本文是机器对话专题的第一篇~ 本篇主要介绍对话系统的基本构成，以及第一个模块 -- 对话理解模块。

### 1. 对话系统简介

对话系统大致可以分为任务型对话(Task-Oriented Systems) 和闲聊对话(Social Chatbot), 也有的任务型对话系统同时具备闲聊的属性。

对话系统一般由四个模块构成：

- Natural Language Understanding (**NLU**)模块: 对用户的utterance进行理解，包括意图识别和槽位填充；例如：

> "I need something that is in the east part of the town" -> "Inform: location = east"

- Dialog State Tracking (**DST**) 模块: 以每个对话turn的NLU模块输出作为输入，输出的是dialog state。例如：

> "USR: I am looking for a moderate price ranged Italian restaurant; SYS: De luca cucina is a modern European restaurant in the center; USR: I need something that is in the east part of the town."
> -> "inform: price = moderate, location = east"

- Dialog Policy Planning (**DPL**) 模块: 输入是DST模块输出的dialog state，输出的是dialog act（包括intent 和 slot-value pairs）。例如：

> "inform: price = moderate, location = east" -> "provide: restaurant_name = Curry prince, price = moderate, address = 452 newmarket road"

- Natural Language Generation (**NLG**) 模块：输入是dialog act，输出一句完整的、通顺的话，作为机器的回复。例如：

> "provide: restaurant_name = Curry prince, price = moderate, address = 452 newmarket road" -> "Curry Prince is moderately priced and located at 452 newmarket road."

当然了，分成四个独立模块也有弊端 -- 错误会在模块之间传播，模型也比较难更新，而且每个模块都需要大量的数据标注。所以，使用**end-to-end**模型也是一个很好的做法。在这个系列中，我会对这四个模块，以及end-to-end模型都进行介绍。

### 2. 对话理解(NLU)模块

**2.1 简介**

NLU模块个人感觉是这四个模块中实现最为简单的，因为它只涉及到分类问题；但是对话内容理解作为整个对话系统的最上游模块，其重要性自然不言而喻。

在NLU中，意图识别(Intent Detection)和槽位填充(Slot Filling) 是两个重要的子任务。其中，意图识别可以看做是一个典型的**分类**任务；槽位填充可以看做是一个**序列标注**任务（可以用CRF，RNN解决）。在早期的系统中，通常的做法是将两者拆分成两个独立的子任务。但这种做法跟人类的语言理解方式是不一致的，事实上我们在实践中发现，两者很多时候具有较强相关性，slot-filling任务很多时候是依赖于intent的：例如，如果一句话的intent被识别为"WatchMovie", 那么slot name更有可能会是"movie_name"而非"music_name".

**2.2 公开数据集**

2.2.1. ATIS (1990)

链接：[The ATIS Spoken Language Systems Pilot Corpus (aclanthology.org)](https://link.zhihu.com/?target=https%3A//aclanthology.org/H90-1021.pdf)

航空领域的语料，规模很小（训练集4400+，测试集800+）。意图识别和槽位填充的难度不大，目前两个任务的F值都已经在95+以上了。唯一可以挑战的是Sentence Acc，即句子的意图、槽位同时正确才算该样本预测正确。

例子：

![img](https://picx.zhimg.com/80/v2-5de1f24a1bf1db62321858fe2a1cb1fd_1440w.png)

2.SNIPS (2018)

链接：[1805.10190.pdf (arxiv.org)](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1805.10190.pdf)

SNIPS数据集涵盖了7个用户intent，包含16,000+多个样本。其中训练集有13,084个样本，验证集和测试集各有700个样本（每个intent有100个样本）。

- SearchCreativeWork (e.g. Find me the *I, Robot* television show),
- GetWeather (e.g. Is it windy in Boston, MA right now?),
- BookRestaurant (e.g. I want to book a highly rated restaurant in Paris tomorrow night),
- PlayMusic (e.g. Play the last track from Beyoncé off Spotify),
- AddToPlaylist (e.g. Add Diamonds to my roadtrip playlist),
- RateBook (e.g. Give 6 stars to Of Mice and Men),
- SearchScreeningEvent (e.g. Check the showtimes for Wonder Woman in Paris).

**2.3 代表论文**

2.3.1 Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling （2016）

本文使用带注意力机制的encoder-decoder模型，来把alignment信息引入到slot filling任务中。

encoder模型就是用的Bi-LSTM, 最后一个hidden state作为encoder的输出。decoder是单向的LSTM，第i步的hidden state si 的计算方法如下：

si=f(si−1,yi−1,hi,ci)

其中， yi−1 是i-1时刻decoder的输出标签（实际操作时还需要经过一层Embedding处理）； hi 代表当前时刻encoder的隐层状态， si−1 代表上一时刻的decoder隐层状态。而 ci 则是encoder states的注意力加权：

![img](https://picx.zhimg.com/80/v2-ba8508aee8253b29c6b8dfff4be976aa_1440w.png)

模型示意图：

![img](https://picx.zhimg.com/80/v2-4358a7527706f3147db55c076847ed7d_1440w.png)




2.3.2 A Stack-Propagation Framework with Token-Level Intent Detection for Spoken Language Understanding (2018)

前面我们提到过，很多时候slot-filling任务是非常以来intent detection的。那么，比起上一篇论文那样类似multi-task的建模方式，似乎应该更加显式地利用好intent信息。标题中的"Stack"表示的正是这个意思：用intent detection的输出作为slot-filling任务的输入。但是，这会带来error propagation，所以作者还提出用token-level intent detection来进一步增强intent detection的准确率。

本文提出的模型由一个encoder和两个decoder构成。在encoder模块，使用BiLSTM+self-attention来把握每个token的上下文表示。然后，负责intent detection的decoder以self-attention层的输出作为输入，使用单向LSTM来对每个token都进行意图分类：

hiI=f(hi−1I,yi−1I,ei)

其中， hiI 是第i个token的hidden state， yi−1I 是前一个位置输出的slot label， ei 是encoder对第i个token的输出。之后用分类头进行意图分类即可。使用token-level的意图识别，主要是为了发挥类似"ensemble"的效果 -- 如果只使用整句话的信息进行分类，一旦分类错误，错误就会传播到下游的slot filling任务中；token-level意图识别能够为每个token都提供相应的feature，而不是使用同样的feature，降低了错误带来的损害。最终的意图就是所有token进行多数投票的结果，这也正体现了ensemble的思想。

最后，负责slot-filling的decoder以intent detection decoder的输出、encoder的输出作为输入，使用单向LSTM来预测每个token的槽位信息：

hiS=f(hi−1S,yi−1S,yiI⊕ei)

可以看出，这里利用了intent detection decoder的输出 yiI 和encoder的输出 ei 。slot filling的输出就是 hiS 经过分类头的结果。