# 各种损失函数

### 1. torch.nn.CrossEntropyLoss

**CrossEntropyLoss函数 包含Softmax,层和 NLLLoss层,适用于单标签分类问题**

`nn.crossEntropyLoss`就是直接去拿logits和ground truth label进行比较，并不用提前做softmax！

```python
import torch
import torch.nn as nn
import math

criterion = nn.CrossEntropyLoss()
input = torch.Tensor([[-0.7715, -0.6205,-0.2562]]) ##输出的未经归一化的logits
target = torch.tensor([0])
loss = criterion(input, target)
print(loss)  ##1.3447
```

实际上，`nn.crossEntropyLoss`相当于nn.Softmax+log+nn.NLLLoss

```python
import numpy as np
m = nn.Softmax()
input=m(input)  ##做softmax归一，输出为[0.2606, 0.3031, 0.4363]
print(-np.log(0.2606)) ##这就是loss，为1.3447
```

![img](https://pic3.zhimg.com/80/v2-423f83896fca1af3179f203c062fdf55_1440w.png)



### 2. torch.nn.BCELoss

数学公式为Loss = -w * [p * log(q) + (1-p) * log(1-q)]，其中p、q分别为理论标签、实际预测值，w为权重。这里的log对应数学上的ln。计算目标值和预测值之间的二进制交叉熵损失函数。



### 3. torch.nn.BCEWithLogitsLoss

BCEWithLogitsLoss函数包括了 **Sigmoid** 层和 **BCELoss** 层. **适用于多标签分类任务**

在图片多标签分类时，如果3张图片分3类，会输出一个3*3的矩阵。

![img](https://upload-images.jianshu.io/upload_images/16123348-40ca1f907a13ffd6.png?imageMogr2/auto-orient/strip|imageView2/2/w/1128/format/webp)



![img](https://pica.zhimg.com/80/v2-857bddaf45b85052cc441321787d04e2_1440w.png)



![img](https://pic3.zhimg.com/80/v2-8931a99490a4baac1ae79e9e8d4b86a8_1440w.png)









